{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Quality Training Sets at Scale with SageMaker GroundTruth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this lab you'll experience the end to end process of managing a quality training set at scale through Amazon SageMaker Ground Truth.\n",
    "\n",
    "Ths purpose of this notebook is to download and filter out a sample of 10 bird images from Google's Open Images Dataset. The remainder of the lab will be driven through the AWS console. The lab guide can be downloaded from [here](https://github.com/dylan-tong-aws/aws-cv-jumpstarter/blob/master/notebooks/lab3-gluoncv-on-sagemaker.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Replace <<'PROVIDE YOUR BUCKET NAME HERE'>> with the name of your bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "BUCKET = 'dtong-cv-jumpstarter-workshop'\n",
    "#BUCKET = '<<PROVIDE YOUR BUCKET NAME HERE>>'\n",
    "S3_PREFIX = 'ground-truth-lab' # Any valid S3 prefix.\n",
    "\n",
    "# Make sure the bucket is in the same region as this notebook.\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.session.Session().region_name\n",
    "s3 = boto3.client('s3')\n",
    "bucket_region = s3.head_bucket(Bucket=BUCKET)['ResponseMetadata']['HTTPHeaders']['x-amz-bucket-region']\n",
    "\n",
    "assert bucket_region == region, \"Your S3 bucket {} and this notebook need to be in the same region.\".format(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable N_IMGS is set to 10 by default. This will result in the proceeding script to retrieve 10 images of birds. We keep the number of images in this lab to a minimum, so that the time it takes to complete annotation tasks is practical for the purpose of the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMGS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script below to filter N_IMGS from Google's Open Image Datasets, and upload them to your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-23 01:25:44--  https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.164.112, 2607:f8b0:400a:803::2010\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.164.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 52174204 (50M) [text/csv]\n",
      "Saving to: ‘test-annotations-bbox.csv.3’\n",
      "\n",
      "test-annotations-bb 100%[===================>]  49.76M  50.1MB/s    in 1.0s    \n",
      "\n",
      "2019-05-23 01:25:46 (50.1 MB/s) - ‘test-annotations-bbox.csv.3’ saved [52174204/52174204]\n",
      "\n",
      "--2019-05-23 01:25:46--  https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.194.176, 2607:f8b0:400a:804::2010\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.194.176|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 86291 (84K) [text/csv]\n",
      "Saving to: ‘bbox_labels_600_hierarchy.json.3’\n",
      "\n",
      "bbox_labels_600_hie 100%[===================>]  84.27K  --.-KB/s    in 0.06s   \n",
      "\n",
      "2019-05-23 01:25:46 (1.29 MB/s) - ‘bbox_labels_600_hierarchy.json.3’ saved [86291/86291]\n",
      "\n",
      "Copying image 0 / 10\n",
      "Copying image 1 / 10\n",
      "Copying image 2 / 10\n",
      "Copying image 3 / 10\n",
      "Copying image 4 / 10\n",
      "Copying image 5 / 10\n",
      "Copying image 6 / 10\n",
      "Copying image 7 / 10\n",
      "Copying image 8 / 10\n",
      "Copying image 9 / 10\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Download and process the Open Images annotations.\n",
    "!wget https://storage.googleapis.com/openimages/2018_04/test/test-annotations-bbox.csv\n",
    "!wget https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json\n",
    "    \n",
    "with open('bbox_labels_600_hierarchy.json', 'r') as f:\n",
    "    hierarchy = json.load(f)\n",
    "    \n",
    "CLASS_NAME = 'Bird'\n",
    "CLASS_ID = '/m/015p6'\n",
    "\n",
    "# Find all the subclasses of the desired image class (e.g. 'swans' and 'pigeons' etc if CLASS_NAME=='Bird').\n",
    "good_subclasses = set()\n",
    "def get_all_subclasses(hierarchy, good_subtree=False):\n",
    "    if hierarchy['LabelName'] == CLASS_ID:\n",
    "        good_subtree = True\n",
    "    if good_subtree:\n",
    "        good_subclasses.add(hierarchy['LabelName'])\n",
    "    if 'Subcategory' in hierarchy:            \n",
    "        for subcat in hierarchy['Subcategory']:\n",
    "            get_all_subclasses(subcat, good_subtree=good_subtree)\n",
    "    return good_subclasses\n",
    "good_subclasses = get_all_subclasses(hierarchy)\n",
    "    \n",
    "fids2bbs = defaultdict(list)\n",
    "# Skip images with risky content.\n",
    "skip_these_images = ['251d4c429f6f9c39', \n",
    "                    '065ad49f98157c8d']\n",
    "\n",
    "with open('test-annotations-bbox.csv', 'r') as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        line = line.strip().split(',')\n",
    "        img_id, _, cls_id, conf, xmin, xmax, ymin, ymax, *_ = line\n",
    "        if img_id in skip_these_images:\n",
    "            continue\n",
    "        if cls_id in good_subclasses:\n",
    "            fids2bbs[img_id].append([CLASS_NAME, xmin, xmax, ymin, ymax])\n",
    "            if len(fids2bbs) == N_IMGS:\n",
    "                break\n",
    "\n",
    "# Copy the images to our local bucket.\n",
    "s3 = boto3.client('s3')\n",
    "for img_id_id, img_id in enumerate(fids2bbs.keys()):\n",
    "    if img_id_id % math.floor(N_IMGS/10) == 0:\n",
    "        print('Copying image {} / {}'.format(img_id_id, N_IMGS))\n",
    "    copy_source = {\n",
    "        'Bucket': 'open-images-dataset',\n",
    "        'Key': 'test/{}.jpg'.format(img_id)\n",
    "    }\n",
    "    s3.copy(copy_source, BUCKET, '{}/images/{}.jpg'.format(S3_PREFIX, img_id))\n",
    "print('Done!')\n",
    "\n",
    "# Create and upload the input manifest.\n",
    "manifest_name = 'input.manifest'\n",
    "with open(manifest_name, 'w') as f:\n",
    "    for img_id_id, img_id in enumerate(fids2bbs.keys()):\n",
    "        img_path = 's3://{}/{}/images/{}.jpg'.format(BUCKET, S3_PREFIX, img_id)\n",
    "        f.write('{\"source-ref\": \"' + img_path +'\"}\\n')\n",
    "s3.upload_file(manifest_name, BUCKET, S3_PREFIX + '/' + manifest_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
